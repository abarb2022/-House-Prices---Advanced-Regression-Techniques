{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tips_tricks_35_loading_kaggle_data_to_colab.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abarb2022/-House-Prices---Advanced-Regression-Techniques/blob/main/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlwSaX9akGfG",
        "outputId": "95e75fc2-79f3-4975-f284-f9bd4bae1921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the Google drive so you can store your kaggle API credentials for future use"
      ],
      "metadata": {
        "id": "rw0DfSAggHED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGineQt7dErh",
        "outputId": "1eccd2ec-6643-4f68-ed45-b23c7d9c1982"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a directory for kaggle at the temporary instance location on Colab drive.\n",
        "\n",
        "Download your kaggle API key (.json file). You can do this by going to your kaggle account page and clicking 'Create new API token' under the API section."
      ],
      "metadata": {
        "id": "Rvmi3WbigOmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vhywUxLXgjBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ZTkKggcylXfa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to copy the kaggle API credentials to the temporary location... (I recommend placing it on your Google Drive)"
      ],
      "metadata": {
        "id": "rKv_7jNggXv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "DD56NrWmlb5V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file to Google Drive and then copy to the temporary location."
      ],
      "metadata": {
        "id": "p3N4it0xrFmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IQq6ZMyTrEfO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the file permissions to read/write to the owner only"
      ],
      "metadata": {
        "id": "p3dHJgtLehrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7ncAtrq2lg5F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Competitions and Datasets are the two types of Kaggle data**"
      ],
      "metadata": {
        "id": "Rb3Zm9VMlu3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Download competition data**\n",
        "\n",
        "If you get 403 Forbidden error, you need to click 'Late Submission' on the Kaggle page for that competition."
      ],
      "metadata": {
        "id": "OrdSFfGjl3Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c gan-getting-started"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yNdtoRln8A",
        "outputId": "b9d2c7bf-03ab-42df-ac58-9e7ee8452285"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gan-getting-started.zip to /content\n",
            " 87% 320M/367M [00:06<00:01, 38.2MB/s]\n",
            "100% 367M/367M [00:06<00:00, 58.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip, in case the downloaded file is zipped. Refresh the files on the left hand side to update the view."
      ],
      "metadata": {
        "id": "fRmXZnHghNAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip gan-getting-started"
      ],
      "metadata": {
        "id": "dAs9oVnNoziL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/cyclegan_checkpoints\n"
      ],
      "metadata": {
        "id": "ASf4KPExG7IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "\n",
        "# ============================================\n",
        "# 1. GENERATOR (FROM SCRATCH)\n",
        "# ============================================\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, padding=1, padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels, channels, 3, padding=1, padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, num_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 7, padding=3, padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Downsampling\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Residual blocks\n",
        "        res_blocks = []\n",
        "        for _ in range(num_residual_blocks):\n",
        "            res_blocks.append(ResidualBlock(256))\n",
        "        self.res_blocks = nn.Sequential(*res_blocks)\n",
        "\n",
        "        # Upsampling\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Output\n",
        "        self.output = nn.Sequential(\n",
        "            nn.Conv2d(64, out_channels, 7, padding=3, padding_mode='reflect'),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.down1(x)\n",
        "        x = self.down2(x)\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# ============================================\n",
        "# 2. DISCRIMINATOR (FROM SCRATCH)\n",
        "# ============================================\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ============================================\n",
        "# 3. DATASET\n",
        "# ============================================\n",
        "class MonetDataset(Dataset):\n",
        "    def __init__(self, photo_dir, monet_dir, img_size=256):\n",
        "        self.photo_files = [os.path.join(photo_dir, f) for f in os.listdir(photo_dir)]\n",
        "        self.monet_files = [os.path.join(monet_dir, f) for f in os.listdir(monet_dir)]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.photo_files), len(self.monet_files))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        photo_path = self.photo_files[idx % len(self.photo_files)]\n",
        "        monet_path = random.choice(self.monet_files)\n",
        "\n",
        "        photo = Image.open(photo_path).convert('RGB')\n",
        "        monet = Image.open(monet_path).convert('RGB')\n",
        "\n",
        "        return self.transform(photo), self.transform(monet)"
      ],
      "metadata": {
        "id": "mopceIk8Hl78"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cyclegan(\n",
        "    photo_dir='data/photo_jpg',\n",
        "    monet_dir='data/monet_jpg',\n",
        "    num_epochs=30,\n",
        "    batch_size=1,\n",
        "    checkpoint_dir='/content/drive/MyDrive/cyclegan_checkpoints',\n",
        "    save_every=5,\n",
        "    use_wandb=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Train CycleGAN from scratch\n",
        "    \"\"\"\n",
        "    # Device\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"üöÄ Using device: {device}\")\n",
        "\n",
        "    # Data\n",
        "    print(\"üìÅ Loading data...\")\n",
        "    dataset = MonetDataset(photo_dir, monet_dir)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    print(f\"‚úÖ Loaded {len(dataset)} samples\")\n",
        "\n",
        "    # Models\n",
        "    print(\"üèóÔ∏è  Creating models...\")\n",
        "    gen_A2B = Generator().to(device)\n",
        "    gen_B2A = Generator().to(device)\n",
        "    disc_A = Discriminator().to(device)\n",
        "    disc_B = Discriminator().to(device)\n",
        "\n",
        "    # Optimizers\n",
        "    opt_G = optim.Adam(\n",
        "        list(gen_A2B.parameters()) + list(gen_B2A.parameters()),\n",
        "        lr=0.0002, betas=(0.5, 0.999)\n",
        "    )\n",
        "    opt_D = optim.Adam(\n",
        "        list(disc_A.parameters()) + list(disc_B.parameters()),\n",
        "        lr=0.0002, betas=(0.5, 0.999)\n",
        "    )\n",
        "\n",
        "    # Loss functions (FROM SCRATCH)\n",
        "    mse_loss = nn.MSELoss()\n",
        "    l1_loss = nn.L1Loss()\n",
        "    lambda_cycle = 10.0\n",
        "    lambda_identity = 5.0\n",
        "\n",
        "    # WandB\n",
        "    if use_wandb:\n",
        "        wandb.init(project='cyclegan-monet', config={\n",
        "            'epochs': num_epochs,\n",
        "            'batch_size': batch_size,\n",
        "            'lambda_cycle': lambda_cycle,\n",
        "            'lambda_identity': lambda_identity\n",
        "        })\n",
        "\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Training loop\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üé® STARTING TRAINING\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        gen_A2B.train()\n",
        "        gen_B2A.train()\n",
        "        disc_A.train()\n",
        "        disc_B.train()\n",
        "\n",
        "        epoch_losses = {'G': 0, 'D': 0, 'Cycle': 0}\n",
        "\n",
        "        pbar = tqdm(dataloader, desc=f'Epoch {epoch}/{num_epochs}')\n",
        "        for real_A, real_B in pbar:\n",
        "            real_A, real_B = real_A.to(device), real_B.to(device)\n",
        "\n",
        "            # ==================\n",
        "            # TRAIN GENERATORS\n",
        "            # ==================\n",
        "            opt_G.zero_grad()\n",
        "\n",
        "            # Generate fakes\n",
        "            fake_B = gen_A2B(real_A)\n",
        "            fake_A = gen_B2A(real_B)\n",
        "\n",
        "            # Cycle consistency\n",
        "            reconstructed_A = gen_B2A(fake_B)\n",
        "            reconstructed_B = gen_A2B(fake_A)\n",
        "\n",
        "            # Identity\n",
        "            identity_A = gen_B2A(real_A)\n",
        "            identity_B = gen_A2B(real_B)\n",
        "\n",
        "            # Adversarial loss (LSGAN - FROM SCRATCH)\n",
        "            pred_fake_B = disc_B(fake_B)\n",
        "            pred_fake_A = disc_A(fake_A)\n",
        "            loss_adv_B = mse_loss(pred_fake_B, torch.ones_like(pred_fake_B))\n",
        "            loss_adv_A = mse_loss(pred_fake_A, torch.ones_like(pred_fake_A))\n",
        "\n",
        "            # Cycle consistency loss (FROM SCRATCH)\n",
        "            loss_cycle_A = l1_loss(reconstructed_A, real_A)\n",
        "            loss_cycle_B = l1_loss(reconstructed_B, real_B)\n",
        "            loss_cycle = (loss_cycle_A + loss_cycle_B) * lambda_cycle\n",
        "\n",
        "            # Identity loss (FROM SCRATCH)\n",
        "            loss_identity_A = l1_loss(identity_A, real_A)\n",
        "            loss_identity_B = l1_loss(identity_B, real_B)\n",
        "            loss_identity = (loss_identity_A + loss_identity_B) * lambda_identity\n",
        "\n",
        "            # Total generator loss\n",
        "            loss_G = loss_adv_A + loss_adv_B + loss_cycle + loss_identity\n",
        "            loss_G.backward()\n",
        "            opt_G.step()\n",
        "\n",
        "            # =======================\n",
        "            # TRAIN DISCRIMINATORS\n",
        "            # =======================\n",
        "            opt_D.zero_grad()\n",
        "\n",
        "            # Discriminator A (FROM SCRATCH)\n",
        "            pred_real_A = disc_A(real_A)\n",
        "            pred_fake_A = disc_A(fake_A.detach())\n",
        "            loss_real_A = mse_loss(pred_real_A, torch.ones_like(pred_real_A))\n",
        "            loss_fake_A = mse_loss(pred_fake_A, torch.zeros_like(pred_fake_A))\n",
        "            loss_D_A = (loss_real_A + loss_fake_A) * 0.5\n",
        "\n",
        "            # Discriminator B (FROM SCRATCH)\n",
        "            pred_real_B = disc_B(real_B)\n",
        "            pred_fake_B = disc_B(fake_B.detach())\n",
        "            loss_real_B = mse_loss(pred_real_B, torch.ones_like(pred_real_B))\n",
        "            loss_fake_B = mse_loss(pred_fake_B, torch.zeros_like(pred_fake_B))\n",
        "            loss_D_B = (loss_real_B + loss_fake_B) * 0.5\n",
        "\n",
        "            loss_D = loss_D_A + loss_D_B\n",
        "            loss_D.backward()\n",
        "            opt_D.step()\n",
        "\n",
        "            # Track losses\n",
        "            epoch_losses['G'] += loss_G.item()\n",
        "            epoch_losses['D'] += loss_D.item()\n",
        "            epoch_losses['Cycle'] += loss_cycle.item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'G': f\"{loss_G.item():.3f}\",\n",
        "                'D': f\"{loss_D.item():.3f}\",\n",
        "                'Cycle': f\"{loss_cycle.item():.3f}\"\n",
        "            })\n",
        "\n",
        "        # Average losses\n",
        "        for k in epoch_losses:\n",
        "            epoch_losses[k] /= len(dataloader)\n",
        "\n",
        "        # Log\n",
        "        if use_wandb:\n",
        "            wandb.log({'epoch': epoch, **epoch_losses})\n",
        "\n",
        "        print(f\"\\nüìä Epoch {epoch}: G={epoch_losses['G']:.4f}, D={epoch_losses['D']:.4f}, Cycle={epoch_losses['Cycle']:.4f}\\n\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if epoch % save_every == 0 or epoch == num_epochs:\n",
        "            checkpoint_path = f\"{checkpoint_dir}/checkpoint_epoch_{epoch}.pth\"\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'gen_A2B': gen_A2B.state_dict(),\n",
        "                'gen_B2A': gen_B2A.state_dict(),\n",
        "                'disc_A': disc_A.state_dict(),\n",
        "                'disc_B': disc_B.state_dict(),\n",
        "            }, checkpoint_path)\n",
        "            print(f\"üíæ Saved: {checkpoint_path}\\n\")\n",
        "\n",
        "    print(\"\\n‚úÖ TRAINING COMPLETE!\")\n",
        "    if use_wandb:\n",
        "        wandb.finish()\n",
        "\n",
        "    return gen_A2B, gen_B2A"
      ],
      "metadata": {
        "id": "fdxhmduQLm_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epj79_JCNFSg",
        "outputId": "1cb54779-1022-4aa8-98d2-ba721205672f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabarb2022\u001b[0m (\u001b[33mabarb2022-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_A2B, gen_B2A = train_cyclegan(\n",
        "    photo_dir='photo_jpg',\n",
        "    monet_dir='monet_jpg',\n",
        "    num_epochs=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "collapsed": true,
        "id": "se0JWdI3NUlW",
        "outputId": "1a383c06-4fbd-4f38-c0dc-c0d810945e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Using device: cpu\n",
            "üìÅ Loading data...\n",
            "‚úÖ Loaded 7038 samples\n",
            "üèóÔ∏è  Creating models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-306301355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gen_A2B, gen_B2A = train_cyclegan(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mphoto_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'photo_jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmonet_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'monet_jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/tmp/ipython-input-1924663254.py\u001b[0m in \u001b[0;36mtrain_cyclegan\u001b[0;34m(photo_dir, monet_dir, num_epochs, batch_size, checkpoint_dir, save_every, use_wandb)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# WandB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_wandb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         wandb.init(project='cyclegan-monet', config={\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings, anonymous)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_telemetry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m         \u001b[0mrun_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_warnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_run_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36mmaybe_login\u001b[0;34m(self, init_settings)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Calling login() may change settings on the singleton,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# so these may not be the final run settings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mrun_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36msettings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \"\"\"\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             self._load_settings(\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0msystem_settings_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mdisable_sagemaker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_load_settings\u001b[0;34m(self, system_settings_path, disable_sagemaker, overrides)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# infer settings from the system environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_system_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# load SageMaker settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36mupdate_from_system_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1826\u001b[0m         \u001b[0;31m# Attempt to get notebook information if not already set by the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m             \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mnotebook_metadata\u001b[0;34m(silent)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# Colab:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# request the most recent contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mipynb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_colab_load_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mipynb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mjupyter_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             return {\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mattempt_colab_load_ipynb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# This isn't thread safe, never call in a thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ipynb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_training(\n",
        "    checkpoint_path='/content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_5.pth',\n",
        "    photo_dir='photo_jpg',\n",
        "    monet_dir='monet_jpg',\n",
        "    num_epochs=25,\n",
        "    batch_size=1,\n",
        "    checkpoint_dir='/content/drive/MyDrive/cyclegan_checkpoints',\n",
        "    save_every=1,\n",
        "    wandb_run_id=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Resume training from checkpoint\n",
        "    Will start from epoch 6 if checkpoint is epoch 5\n",
        "    \"\"\"\n",
        "\n",
        "    # Check device\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"üöÄ Using device: {device}\")\n",
        "\n",
        "    if device == 'cpu':\n",
        "        print(\"‚ö†Ô∏è  WARNING: No GPU detected!\")\n",
        "        print(\"    Training on CPU will take 50x longer!\")\n",
        "        print(\"    Please reconnect to GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
        "        return None, None\n",
        "\n",
        "    # Load checkpoint\n",
        "    print(f\"üìÇ Loading checkpoint: {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print(f\"‚úÖ Loaded checkpoint from epoch {start_epoch}\")\n",
        "    print(f\"üéØ Will train from epoch {start_epoch + 1} to {num_epochs}\")\n",
        "\n",
        "    # Data\n",
        "    print(\"\\nüìÅ Loading data...\")\n",
        "    dataset = MonetDataset(photo_dir, monet_dir)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "    print(f\"‚úÖ Loaded {len(dataset)} samples\")\n",
        "\n",
        "    # Models\n",
        "    print(\"\\nüèóÔ∏è  Creating models...\")\n",
        "    gen_A2B = Generator().to(device)\n",
        "    gen_B2A = Generator().to(device)\n",
        "    disc_A = Discriminator().to(device)\n",
        "    disc_B = Discriminator().to(device)\n",
        "\n",
        "    # Load weights\n",
        "    print(\"‚öôÔ∏è  Loading model weights from checkpoint...\")\n",
        "    gen_A2B.load_state_dict(checkpoint['gen_A2B'])\n",
        "    gen_B2A.load_state_dict(checkpoint['gen_B2A'])\n",
        "    disc_A.load_state_dict(checkpoint['disc_A'])\n",
        "    disc_B.load_state_dict(checkpoint['disc_B'])\n",
        "    print(\"‚úÖ All model weights loaded!\")\n",
        "\n",
        "    # Optimizers\n",
        "    opt_G = optim.Adam(\n",
        "        list(gen_A2B.parameters()) + list(gen_B2A.parameters()),\n",
        "        lr=0.0002, betas=(0.5, 0.999)\n",
        "    )\n",
        "    opt_D = optim.Adam(\n",
        "        list(disc_A.parameters()) + list(disc_B.parameters()),\n",
        "        lr=0.0002, betas=(0.5, 0.999)\n",
        "    )\n",
        "\n",
        "    # Load optimizer states if available\n",
        "    if 'opt_G' in checkpoint:\n",
        "        print(\"‚öôÔ∏è  Loading optimizer states...\")\n",
        "        opt_G.load_state_dict(checkpoint['opt_G'])\n",
        "        opt_D.load_state_dict(checkpoint['opt_D'])\n",
        "        print(\"‚úÖ Optimizer states loaded!\")\n",
        "\n",
        "    # Loss functions\n",
        "    mse_loss = nn.MSELoss()\n",
        "    l1_loss = nn.L1Loss()\n",
        "    lambda_cycle = 10.0\n",
        "    lambda_identity = 5.0\n",
        "\n",
        "    # WandB\n",
        "    print(\"\\nüåê Initializing WandB...\")\n",
        "    if wandb_run_id:\n",
        "        print(f\"   Resuming run: {wandb_run_id}\")\n",
        "        wandb.init(\n",
        "            project='cyclegan-monet',\n",
        "            id=wandb_run_id,\n",
        "            resume='must'\n",
        "        )\n",
        "    else:\n",
        "        print(\"   Creating new run\")\n",
        "        wandb.init(\n",
        "            project='cyclegan-monet',\n",
        "            config={\n",
        "                'resumed_from': start_epoch,\n",
        "                'target_epochs': num_epochs,\n",
        "                'lambda_cycle': lambda_cycle,\n",
        "                'lambda_identity': lambda_identity\n",
        "            }\n",
        "        )\n",
        "\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Training loop\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üé® RESUMING TRAINING\")\n",
        "    print(f\"   Starting from: Epoch {start_epoch + 1}\")\n",
        "    print(f\"   Training until: Epoch {num_epochs}\")\n",
        "    print(f\"   Total remaining: {num_epochs - start_epoch} epochs\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    for epoch in range(start_epoch + 1, num_epochs + 1):\n",
        "        gen_A2B.train()\n",
        "        gen_B2A.train()\n",
        "        disc_A.train()\n",
        "        disc_B.train()\n",
        "\n",
        "        epoch_losses = {'G': 0, 'D': 0, 'Cycle': 0}\n",
        "\n",
        "        pbar = tqdm(dataloader, desc=f'Epoch {epoch}/{num_epochs}')\n",
        "        for real_A, real_B in pbar:\n",
        "            real_A, real_B = real_A.to(device), real_B.to(device)\n",
        "\n",
        "            # TRAIN GENERATORS\n",
        "            opt_G.zero_grad()\n",
        "\n",
        "            fake_B = gen_A2B(real_A)\n",
        "            fake_A = gen_B2A(real_B)\n",
        "\n",
        "            reconstructed_A = gen_B2A(fake_B)\n",
        "            reconstructed_B = gen_A2B(fake_A)\n",
        "\n",
        "            identity_A = gen_B2A(real_A)\n",
        "            identity_B = gen_A2B(real_B)\n",
        "\n",
        "            pred_fake_B = disc_B(fake_B)\n",
        "            pred_fake_A = disc_A(fake_A)\n",
        "            loss_adv_B = mse_loss(pred_fake_B, torch.ones_like(pred_fake_B))\n",
        "            loss_adv_A = mse_loss(pred_fake_A, torch.ones_like(pred_fake_A))\n",
        "\n",
        "            loss_cycle_A = l1_loss(reconstructed_A, real_A)\n",
        "            loss_cycle_B = l1_loss(reconstructed_B, real_B)\n",
        "            loss_cycle = (loss_cycle_A + loss_cycle_B) * lambda_cycle\n",
        "\n",
        "            loss_identity_A = l1_loss(identity_A, real_A)\n",
        "            loss_identity_B = l1_loss(identity_B, real_B)\n",
        "            loss_identity = (loss_identity_A + loss_identity_B) * lambda_identity\n",
        "\n",
        "            loss_G = loss_adv_A + loss_adv_B + loss_cycle + loss_identity\n",
        "            loss_G.backward()\n",
        "            opt_G.step()\n",
        "\n",
        "            # TRAIN DISCRIMINATORS\n",
        "            opt_D.zero_grad()\n",
        "\n",
        "            pred_real_A = disc_A(real_A)\n",
        "            pred_fake_A = disc_A(fake_A.detach())\n",
        "            loss_real_A = mse_loss(pred_real_A, torch.ones_like(pred_real_A))\n",
        "            loss_fake_A = mse_loss(pred_fake_A, torch.zeros_like(pred_fake_A))\n",
        "            loss_D_A = (loss_real_A + loss_fake_A) * 0.5\n",
        "\n",
        "            pred_real_B = disc_B(real_B)\n",
        "            pred_fake_B = disc_B(fake_B.detach())\n",
        "            loss_real_B = mse_loss(pred_real_B, torch.ones_like(pred_real_B))\n",
        "            loss_fake_B = mse_loss(pred_fake_B, torch.zeros_like(pred_fake_B))\n",
        "            loss_D_B = (loss_real_B + loss_fake_B) * 0.5\n",
        "\n",
        "            loss_D = loss_D_A + loss_D_B\n",
        "            loss_D.backward()\n",
        "            opt_D.step()\n",
        "\n",
        "            epoch_losses['G'] += loss_G.item()\n",
        "            epoch_losses['D'] += loss_D.item()\n",
        "            epoch_losses['Cycle'] += loss_cycle.item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'G': f\"{loss_G.item():.3f}\",\n",
        "                'D': f\"{loss_D.item():.3f}\",\n",
        "                'Cycle': f\"{loss_cycle.item():.3f}\"\n",
        "            })\n",
        "\n",
        "        # Average losses\n",
        "        for k in epoch_losses:\n",
        "            epoch_losses[k] /= len(dataloader)\n",
        "\n",
        "        # Log to WandB\n",
        "        wandb.log({'epoch': epoch, **epoch_losses})\n",
        "\n",
        "        print(f\"\\nüìä Epoch {epoch}: G={epoch_losses['G']:.4f}, D={epoch_losses['D']:.4f}, Cycle={epoch_losses['Cycle']:.4f}\\n\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if epoch % save_every == 0 or epoch == num_epochs:\n",
        "            checkpoint_path = f\"{checkpoint_dir}/checkpoint_epoch_{epoch}.pth\"\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'gen_A2B': gen_A2B.state_dict(),\n",
        "                'gen_B2A': gen_B2A.state_dict(),\n",
        "                'disc_A': disc_A.state_dict(),\n",
        "                'disc_B': disc_B.state_dict(),\n",
        "                'opt_G': opt_G.state_dict(),\n",
        "                'opt_D': opt_D.state_dict(),\n",
        "            }, checkpoint_path)\n",
        "            print(f\"üíæ Saved: {checkpoint_path}\\n\")\n",
        "\n",
        "    print(\"\\n‚úÖ TRAINING COMPLETE!\")\n",
        "    wandb.finish()\n",
        "\n",
        "    return gen_A2B, gen_B2A"
      ],
      "metadata": {
        "id": "3-SySf7JBKZj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_A2B, gen_B2A = resume_training(\n",
        "    checkpoint_path='/content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_22.pth',\n",
        "    photo_dir='photo_jpg',\n",
        "    monet_dir='monet_jpg',\n",
        "    num_epochs=25,\n",
        "    wandb_run_id='d1vlk1je'\n",
        ")"
      ],
      "metadata": {
        "id": "dWmgrkYjWB6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0dd6e0d3-d599-4dce-eb09-693f7b0c18d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Using device: cuda\n",
            "üìÇ Loading checkpoint: /content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_22.pth\n",
            "‚úÖ Loaded checkpoint from epoch 22\n",
            "üéØ Will train from epoch 23 to 25\n",
            "\n",
            "üìÅ Loading data...\n",
            "‚úÖ Loaded 7038 samples\n",
            "\n",
            "üèóÔ∏è  Creating models...\n",
            "‚öôÔ∏è  Loading model weights from checkpoint...\n",
            "‚úÖ All model weights loaded!\n",
            "‚öôÔ∏è  Loading optimizer states...\n",
            "‚úÖ Optimizer states loaded!\n",
            "\n",
            "üåê Initializing WandB...\n",
            "   Resuming run: d1vlk1je\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251226_115149-d1vlk1je</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je' target=\"_blank\">olive-vortex-5</a></strong> to <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üé® RESUMING TRAINING\n",
            "   Starting from: Epoch 23\n",
            "   Training until: Epoch 25\n",
            "   Total remaining: 3 epochs\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7038/7038 [57:19<00:00,  2.05it/s, G=3.371, D=0.246, Cycle=1.504]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Epoch 23: G=4.1816, D=0.1638, Cycle=1.9433\n",
            "\n",
            "üíæ Saved: /content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_23.pth\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7038/7038 [57:20<00:00,  2.05it/s, G=4.875, D=0.222, Cycle=2.599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 24: G=4.1580, D=0.1618, Cycle=1.9244\n",
            "\n",
            "üíæ Saved: /content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_24.pth\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7038/7038 [57:21<00:00,  2.05it/s, G=3.838, D=0.120, Cycle=1.597]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 25: G=4.1212, D=0.1652, Cycle=1.9109\n",
            "\n",
            "üíæ Saved: /content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_25.pth\n",
            "\n",
            "\n",
            "‚úÖ TRAINING COMPLETE!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cycle</td><td>‚ñà‚ñÑ‚ñÅ</td></tr><tr><td>D</td><td>‚ñÖ‚ñÅ‚ñà</td></tr><tr><td>G</td><td>‚ñà‚ñÖ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÖ‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cycle</td><td>1.91086</td></tr><tr><td>D</td><td>0.16524</td></tr><tr><td>G</td><td>4.12115</td></tr><tr><td>epoch</td><td>25</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">olive-vortex-5</strong> at: <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je</a><br> View project at: <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251226_115149-d1vlk1je/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import wandb\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "wandb.init(\n",
        "    project=\"cyclegan-monet\",\n",
        "    id=\"m2smdjhf\",\n",
        "    resume=\"allow\"\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(\n",
        "    \"/content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_5.pth\",\n",
        "    map_location=torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "gen_A2B = Generator()\n",
        "gen_A2B.load_state_dict(checkpoint[\"gen_A2B\"])\n",
        "gen_A2B.eval()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "\n",
        "photo_dir = \"photo_jpg\"\n",
        "photo_files = sorted(os.listdir(photo_dir))[:5]\n",
        "\n",
        "wandb_images = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for fname in photo_files:\n",
        "        photo_path = os.path.join(photo_dir, fname)\n",
        "\n",
        "        # Load image\n",
        "        photo = Image.open(photo_path).convert(\"RGB\")\n",
        "\n",
        "        # Model input\n",
        "        photo_tensor = transform(photo).unsqueeze(0)\n",
        "\n",
        "        # Generate Monet-style image\n",
        "        fake_monet = gen_A2B(photo_tensor)\n",
        "\n",
        "        fake_monet_img = (\n",
        "            (fake_monet[0] + 1) / 2\n",
        "        ).permute(1, 2, 0).numpy()\n",
        "\n",
        "        photo_vis = np.array(photo.resize((256, 256))) / 255.0\n",
        "\n",
        "        wandb_images.append(\n",
        "            wandb.Image(photo_vis, caption=f\"Input: {fname}\")\n",
        "        )\n",
        "        wandb_images.append(\n",
        "            wandb.Image(fake_monet_img, caption=f\"Output: {fname}\")\n",
        "        )\n",
        "\n",
        "\n",
        "wandb.log({\n",
        "    \"Epoch 25 / Input ‚Üí Monet Samples\": wandb_images\n",
        "})\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "zx1XEpXjBK9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import wandb\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "!pip install pytorch-fid\n",
        "from pytorch_fid import fid_score\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================\n",
        "# STEP 1: Initialize WandB\n",
        "# ============================================\n",
        "wandb.init(\n",
        "    project=\"cyclegan-monet\",\n",
        "    id=\"d1vlk1je\",\n",
        "    resume=\"allow\"\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# STEP 2: Load Checkpoint\n",
        "# ============================================\n",
        "checkpoint = torch.load(\n",
        "    \"/content/drive/MyDrive/cyclegan_checkpoints/checkpoint_epoch_25.pth\",\n",
        "    map_location=torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "gen_A2B = Generator()\n",
        "gen_A2B.load_state_dict(checkpoint[\"gen_A2B\"])\n",
        "gen_A2B.to(device)\n",
        "gen_A2B.eval()\n",
        "\n",
        "# ============================================\n",
        "# STEP 3: Setup transforms\n",
        "# ============================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "\n",
        "# ============================================\n",
        "# STEP 4: Generate images and save for FID\n",
        "# ============================================\n",
        "photo_dir = \"photo_jpg\"\n",
        "monet_dir = \"monet_jpg\"  # Real Monet paintings directory\n",
        "\n",
        "# Create temporary directories for FID calculation\n",
        "generated_dir = \"generated_monet_fid\"\n",
        "os.makedirs(generated_dir, exist_ok=True)\n",
        "\n",
        "photo_files = sorted(os.listdir(photo_dir))\n",
        "wandb_images = []\n",
        "\n",
        "print(f\"üé® Generating images for FID calculation...\")\n",
        "print(f\"Processing {len(photo_files)} photos...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, fname in enumerate(photo_files):\n",
        "        photo_path = os.path.join(photo_dir, fname)\n",
        "\n",
        "        # Load image\n",
        "        photo = Image.open(photo_path).convert(\"RGB\")\n",
        "\n",
        "        # Model input\n",
        "        photo_tensor = transform(photo).unsqueeze(0).to(device)\n",
        "\n",
        "        # Generate Monet-style image\n",
        "        fake_monet = gen_A2B(photo_tensor)\n",
        "\n",
        "        # Convert to image for saving (denormalize)\n",
        "        fake_monet_img = (fake_monet[0].cpu() + 1) / 2\n",
        "        fake_monet_img = fake_monet_img.clamp(0, 1)\n",
        "        fake_monet_pil = transforms.ToPILImage()(fake_monet_img)\n",
        "\n",
        "        # Save generated image for FID calculation\n",
        "        save_path = os.path.join(generated_dir, fname)\n",
        "        fake_monet_pil.save(save_path)\n",
        "\n",
        "        # Log first 5 samples to WandB\n",
        "        if i < 5:\n",
        "            fake_monet_np = fake_monet_img.permute(1, 2, 0).numpy()\n",
        "            photo_vis = np.array(photo.resize((256, 256))) / 255.0\n",
        "\n",
        "            wandb_images.append(\n",
        "                wandb.Image(photo_vis, caption=f\"Input: {fname}\")\n",
        "            )\n",
        "            wandb_images.append(\n",
        "                wandb.Image(fake_monet_np, caption=f\"Output: {fname}\")\n",
        "            )\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"  ‚úì Generated {i + 1}/{len(photo_files)} images\")\n",
        "\n",
        "print(f\"‚úÖ Generated {len(photo_files)} images\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 5: Calculate FID Score\n",
        "# ============================================\n",
        "print(\"\\nüìä Calculating FID score...\")\n",
        "print(f\"  Real Monet dir: {monet_dir}\")\n",
        "print(f\"  Generated dir: {generated_dir}\")\n",
        "\n",
        "try:\n",
        "    fid_value = fid_score.calculate_fid_given_paths(\n",
        "        paths=[monet_dir, generated_dir],\n",
        "        batch_size=50,\n",
        "        device=device,\n",
        "        dims=2048,  # InceptionV3 feature dimension\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    print(f\"\\n‚ú® FID Score: {fid_value:.2f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if fid_value < 50:\n",
        "        quality = \"Excellent! üåü\"\n",
        "    elif fid_value < 100:\n",
        "        quality = \"Good! üëç\"\n",
        "    elif fid_value < 200:\n",
        "        quality = \"Okay üòê\"\n",
        "    else:\n",
        "        quality = \"Needs improvement üìâ\"\n",
        "\n",
        "    print(f\"   Quality: {quality}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error calculating FID: {e}\")\n",
        "    fid_value = None\n",
        "\n",
        "# ============================================\n",
        "# STEP 6: Log everything to WandB\n",
        "# ============================================\n",
        "log_dict = {\n",
        "    \"Epoch 25 / Input ‚Üí Monet Samples\": wandb_images,\n",
        "    \"epoch\": checkpoint.get(\"epoch\", 25)\n",
        "}\n",
        "\n",
        "# Add FID score if calculated successfully\n",
        "if fid_value is not None:\n",
        "    log_dict[\"FID Score\"] = fid_value\n",
        "\n",
        "wandb.log(log_dict)\n",
        "\n",
        "# ============================================\n",
        "# STEP 7: Create comparison table\n",
        "# ============================================\n",
        "if fid_value is not None:\n",
        "    # Create a summary table\n",
        "# Create a summary table\n",
        "# Simpler approach - just log metrics\n",
        "    wandb.log({\n",
        "        \"Epoch 25 / Input ‚Üí Monet Samples\": wandb_images,\n",
        "        \"FID Score\": fid_value,\n",
        "        \"epoch\": checkpoint.get(\"epoch\", 25),\n",
        "        \"num_images_generated\": len(photo_files)\n",
        "    })\n",
        "\n",
        "    print(f\"\\nüìä Summary:\")\n",
        "    print(f\"   FID Score: {fid_value:.2f} ({quality})\")\n",
        "    print(f\"   Images Generated: {len(photo_files)}\")\n",
        "    print(f\"   Checkpoint Epoch: {checkpoint.get('epoch', 25)}\")\n",
        "\n",
        "print(\"\\n‚úÖ Logged to WandB!\")\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R4MxXIfLmbR1",
        "outputId": "304b98c6-dce6-4456-dc6a-e1129c0cb6f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cycle</td><td>1.91086</td></tr><tr><td>D</td><td>0.16524</td></tr><tr><td>FID Score</td><td>86.6775</td></tr><tr><td>G</td><td>4.12115</td></tr><tr><td>epoch</td><td>25</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">olive-vortex-5</strong> at: <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je</a><br> View project at: <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251228_202712-d1vlk1je/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251228_202804-d1vlk1je</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je' target=\"_blank\">olive-vortex-5</a></strong> to <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je' target=\"_blank\">https://wandb.ai/abarb2022-free-university-of-tbilisi-/cyclegan-monet/runs/d1vlk1je</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé® Generating images for FID calculation...\n",
            "Processing 7038 photos...\n",
            "  ‚úì Generated 100/7038 images\n",
            "  ‚úì Generated 200/7038 images\n",
            "  ‚úì Generated 300/7038 images\n",
            "  ‚úì Generated 400/7038 images\n",
            "  ‚úì Generated 500/7038 images\n",
            "  ‚úì Generated 600/7038 images\n",
            "  ‚úì Generated 700/7038 images\n",
            "  ‚úì Generated 800/7038 images\n",
            "  ‚úì Generated 900/7038 images\n",
            "  ‚úì Generated 1000/7038 images\n",
            "  ‚úì Generated 1100/7038 images\n",
            "  ‚úì Generated 1200/7038 images\n",
            "  ‚úì Generated 1300/7038 images\n",
            "  ‚úì Generated 1400/7038 images\n",
            "  ‚úì Generated 1500/7038 images\n",
            "  ‚úì Generated 1600/7038 images\n",
            "  ‚úì Generated 1700/7038 images\n",
            "  ‚úì Generated 1800/7038 images\n",
            "  ‚úì Generated 1900/7038 images\n",
            "  ‚úì Generated 2000/7038 images\n",
            "  ‚úì Generated 2100/7038 images\n",
            "  ‚úì Generated 2200/7038 images\n",
            "  ‚úì Generated 2300/7038 images\n",
            "  ‚úì Generated 2400/7038 images\n",
            "  ‚úì Generated 2500/7038 images\n",
            "  ‚úì Generated 2600/7038 images\n",
            "  ‚úì Generated 2700/7038 images\n",
            "  ‚úì Generated 2800/7038 images\n",
            "  ‚úì Generated 2900/7038 images\n",
            "  ‚úì Generated 3000/7038 images\n",
            "  ‚úì Generated 3100/7038 images\n",
            "  ‚úì Generated 3200/7038 images\n",
            "  ‚úì Generated 3300/7038 images\n",
            "  ‚úì Generated 3400/7038 images\n",
            "  ‚úì Generated 3500/7038 images\n",
            "  ‚úì Generated 3600/7038 images\n",
            "  ‚úì Generated 3700/7038 images\n",
            "  ‚úì Generated 3800/7038 images\n",
            "  ‚úì Generated 3900/7038 images\n",
            "  ‚úì Generated 4000/7038 images\n",
            "  ‚úì Generated 4100/7038 images\n",
            "  ‚úì Generated 4200/7038 images\n",
            "  ‚úì Generated 4300/7038 images\n",
            "  ‚úì Generated 4400/7038 images\n",
            "  ‚úì Generated 4500/7038 images\n",
            "  ‚úì Generated 4600/7038 images\n",
            "  ‚úì Generated 4700/7038 images\n",
            "  ‚úì Generated 4800/7038 images\n",
            "  ‚úì Generated 4900/7038 images\n",
            "  ‚úì Generated 5000/7038 images\n",
            "  ‚úì Generated 5100/7038 images\n",
            "  ‚úì Generated 5200/7038 images\n",
            "  ‚úì Generated 5300/7038 images\n",
            "  ‚úì Generated 5400/7038 images\n",
            "  ‚úì Generated 5500/7038 images\n",
            "  ‚úì Generated 5600/7038 images\n",
            "  ‚úì Generated 5700/7038 images\n",
            "  ‚úì Generated 5800/7038 images\n",
            "  ‚úì Generated 5900/7038 images\n",
            "  ‚úì Generated 6000/7038 images\n",
            "  ‚úì Generated 6100/7038 images\n",
            "  ‚úì Generated 6200/7038 images\n",
            "  ‚úì Generated 6300/7038 images\n",
            "  ‚úì Generated 6400/7038 images\n",
            "  ‚úì Generated 6500/7038 images\n",
            "  ‚úì Generated 6600/7038 images\n",
            "  ‚úì Generated 6700/7038 images\n",
            "  ‚úì Generated 6800/7038 images\n",
            "  ‚úì Generated 6900/7038 images\n",
            "  ‚úì Generated 7000/7038 images\n",
            "‚úÖ Generated 7038 images\n",
            "\n",
            "üìä Calculating FID score...\n",
            "  Real Monet dir: monet_jpg\n",
            "  Generated dir: generated_monet_fid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.75it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [00:40<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® FID Score: 86.68\n",
            "   Quality: Good! üëç\n",
            "\n",
            "üìä Summary:\n",
            "   FID Score: 86.68 (Good! üëç)\n",
            "   Images Generated: 7038\n",
            "   Checkpoint Epoch: 25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'table' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2792209418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Checkpoint Epoch: {checkpoint.get('epoch', 25)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Evaluation Summary\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n‚úÖ Logged to WandB!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_9kUHNU9mq5U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}